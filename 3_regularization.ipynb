{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "## Assignment 3\n",
    "\n",
    "Previously in 2_fullyconnected.ipynb, you trained a logistic regression and a neural network model.\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First reload the data we generated in notmist.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "\n",
    "* data as a flat matrix,\n",
    "* labels as float 1-hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1)==  np.argmax(labels, 1))\n",
    "            / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Problem 1\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor t using nn.l2_loss(t). The right amount of regularization should improve your validation / test accuracy.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try it on logistics regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_beta = tf.placeholder(tf.float32)\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # Variables\n",
    "    weights = tf.Variable(\n",
    "      tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + tf_beta * tf.nn.l2_loss(weights)\n",
    "    \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "      tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 16.468800\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 15.2%\n",
      "Minibatch loss at step 500: 3.216318\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 1000: 1.665687\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 1500: 1.272375\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 2000: 1.125988\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2500: 0.921402\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 3000: 0.901254\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.8%\n",
      "Test accuracy: 88.6%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels, tf_beta: 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "        [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "              valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets tune our hyperparameter beta\n",
    "I would like to use only the validation set to determine which beta I will use.\n",
    "In addition, I would also like to see how consisting my testset scores with my\n",
    "validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 22710.981689 sec\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "betas = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "valid_scores = []\n",
    "test_scores = []\n",
    "np.random.seed(10)  # set seed\n",
    "\n",
    "# start timer\n",
    "time.clock()\n",
    "for beta in betas:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        for step in range(num_steps):\n",
    "            # Lets use a better randomization across epochs\n",
    "            idx = np.random.randint(low=0, high=train_labels.shape[0], size=batch_size)\n",
    "            batch_data = train_dataset[idx, :]\n",
    "            batch_labels = train_labels[idx, :]\n",
    "            feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels, tf_beta: beta}\n",
    "            _, l, predictions = session.run(\n",
    "            [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "#             if(step % 500 == 0):\n",
    "#                 print(\"Minibatch loss at step %d: %f\" %(step, l))\n",
    "#                 print(\"Minibatch accuracy: %.1f%%\" %accuracy(predictions, batch_labels))\n",
    "#         print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "        valid_scores.append(accuracy(valid_prediction.eval(), valid_labels))\n",
    "#         print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "        test_scores.append(accuracy(test_prediction.eval(), test_labels))\n",
    "# total time\n",
    "print(\"total time: \" + str(time.clock()) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEOCAYAAACEiBAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a0e5a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(betas, valid_scores)\n",
    "plt.grid(True)\n",
    "plt.title(\"Validation Scores(logistics)\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEOCAYAAACEiBAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnHM17v8BPbFlmQpe8XUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d1f8dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(betas, test_scores)\n",
    "plt.grid(True)\n",
    "plt.title(\"Test Scores(logistics)\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intresting! vlidation socres is similar to test scores and both achieved a really high score when beta is 10^-3. However, it was a little bit ambiguious that validation score has the highest at 10^-2.4\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's try it on my very first neural network. Since 10^-3 gives me the highest score for logistics, I would love to see how well it performes on neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_nodes = 1024\n",
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_beta = tf.placeholder(tf.float32)\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # Hidden layer\n",
    "    hidden_weights = tf.Variable(\n",
    "        tf.truncated_normal([image_size * image_size, hidden_nodes]))\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_nodes]))\n",
    "    hidden1 = tf.nn.relu(tf.matmul(tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "    \n",
    "    # Variables\n",
    "    weights2 = tf.Variable(\n",
    "      tf.truncated_normal([hidden_nodes, num_labels]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "     \n",
    "    # Training computation.\n",
    "    logits = tf.matmul(hidden1, weights2) + biases2\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) \\\n",
    "    + tf_beta * (tf.nn.l2_loss(hidden_weights) + tf.nn.l2_loss(weights2))\n",
    "    \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_relu = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "      tf.matmul(valid_relu, weights2) + biases2)\n",
    "    test_relu = tf.nn.relu(tf.matmul(tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_relu, weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2875.524658\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 22.4%\n",
      "Minibatch loss at step 500: 46.595001\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 1000: 1.583724\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 1500: 0.660033\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 2000: 0.851509\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.3%\n",
      "Minibatch loss at step 2500: 0.737090\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 83.8%\n",
      "Minibatch loss at step 3000: 0.741408\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.0%\n",
      "Test accuracy: 90.3%\n",
      "total time: 23593.092904 sec\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    time.clock()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels, tf_beta: 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "            [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" %(step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "                valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "    print(\"total time: \" + str(time.clock()) + ' sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, a little bit better. Finally, achieve 90%. Let's tune beta again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized 0.0001\n",
      "Initialized 0.000125892541179\n",
      "Initialized 0.000158489319246\n",
      "Initialized 0.000199526231497\n",
      "Initialized 0.000251188643151\n",
      "Initialized 0.000316227766017\n",
      "Initialized 0.000398107170553\n",
      "Initialized 0.000501187233627\n",
      "Initialized 0.00063095734448\n",
      "Initialized 0.000794328234724\n",
      "Initialized 0.001\n",
      "Initialized 0.00125892541179\n",
      "Initialized 0.00158489319246\n",
      "Initialized 0.00199526231497\n",
      "Initialized 0.00251188643151\n",
      "Initialized 0.00316227766017\n",
      "Initialized 0.00398107170553\n",
      "Initialized 0.00501187233627\n",
      "Initialized 0.0063095734448\n",
      "Initialized 0.00794328234724\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "betas = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "valid_scores = []\n",
    "test_scores = []\n",
    "best_beta = 0\n",
    "max_valid = 0\n",
    "\n",
    "# start time\n",
    "# time.clock()\n",
    "for beta in betas:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized \" + str(beta))\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels, tf_beta: beta}\n",
    "            _, l, predictions = session.run(\n",
    "            [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        valid_score = accuracy(valid_prediction.eval(), valid_labels)\n",
    "        valid_scores.append(valid_score)\n",
    "        if (valid_score > max_valid):\n",
    "            best_beta = beta\n",
    "            max_valid = valid_score\n",
    "        test_scores.append(accuracy(test_prediction.eval(), test_labels))\n",
    "# print(\"Total time: \" + str(time.clock) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEOCAYAAACD5gx6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11da58fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(betas, valid_scores)\n",
    "plt.grid(True)\n",
    "plt.title(\"2 layers NN Validation Score(logistics)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEOCAYAAACD5gx6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFCQBsjHMhVYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11da580d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(betas, test_scores)\n",
    "plt.grid(True)\n",
    "plt.title(\"2 layers NN Test Score(logistics)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation set is identical to the test set so it is a good indicator for tuning the hyperparameter beta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example restricts batches number to only 5. In addition, we will be choosing offset by step % num_batches(e.g. 0, 1, 2, 3, 4). Let's see how extreme the overfitting will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_nodes = 1024\n",
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_beta = tf.placeholder(tf.float32)\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # Hidden layer\n",
    "    hidden_weights = tf.Variable(\n",
    "        tf.truncated_normal([image_size * image_size, hidden_nodes]))\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_nodes]))\n",
    "    hidden1 = tf.nn.relu(tf.matmul(tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "    \n",
    "    # Variables\n",
    "    weights2 = tf.Variable(\n",
    "      tf.truncated_normal([hidden_nodes, num_labels]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "     \n",
    "    # Training computation.\n",
    "    logits = tf.matmul(hidden1, weights2) + biases2\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) \\\n",
    "    + tf_beta * (tf.nn.l2_loss(hidden_weights) + tf.nn.l2_loss(weights2))\n",
    "    \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_relu = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "      tf.matmul(valid_relu, weights2) + biases2)\n",
    "    test_relu = tf.nn.relu(tf.matmul(tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_relu, weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 706.044739\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 23.7%\n",
      "Minibatch loss at step 500: 191.451172\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 60.2%\n",
      "Test accuracy: 65.8%\n",
      "total time: 29061.846931 sec\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1000\n",
    "num_batches = 3\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    time.clock()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = step % num_batches\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels, tf_beta: 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "            [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" %(step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "                valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "    print(\"total time: \" + str(time.clock()) + ' sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result, we can see the model is doing very well on the training dataset but it fails on the validation dataset and the test dataset because of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides nn.dropout() for that, but you have to make sure it's only inserted during training.\n",
    "What happens to our extreme overfitting case?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_nodes = 1024\n",
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_beta = tf.placeholder(tf.float32)\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # Hidden layer\n",
    "    hidden_weights = tf.Variable(\n",
    "        tf.truncated_normal([image_size * image_size, hidden_nodes]))\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_nodes]))\n",
    "    hidden1 = tf.nn.relu(tf.matmul(tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "    \n",
    "    # Variables\n",
    "    weights2 = tf.Variable(\n",
    "      tf.truncated_normal([hidden_nodes, num_labels]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "     \n",
    "    # Training computation.\n",
    "    hidden1_drop = tf.nn.dropout(hidden1, keep_prob)\n",
    "    logits = tf.matmul(hidden1_drop, weights2) + biases2\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) \\\n",
    "    + tf_beta * (tf.nn.l2_loss(hidden_weights) + tf.nn.l2_loss(weights2))\n",
    "    \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_relu = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "      tf.matmul(valid_relu, weights2) + biases2)\n",
    "    test_relu = tf.nn.relu(tf.matmul(tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_relu, weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 847.693542\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 28.4%\n",
      "Minibatch loss at step 500: 191.396057\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 66.4%\n",
      "Test accuracy: 72.3%\n",
      "total time: 28978.431858 sec\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1000\n",
    "num_batches = 3\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    time.clock()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = step % num_batches\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels, tf_beta: 1e-3,\n",
    "                    keep_prob: 0.5}\n",
    "        _, l, predictions = session.run(\n",
    "            [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" %(step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "                valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "    print(\"total time: \" + str(time.clock()) + ' sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a little jump from 65.8% to 72.3% on the test dataset. Baes on the value 30 rule I can say that the result is significant better by applying dropout on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is 97.1%.\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "\n",
    "* global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "\n",
    "  learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "  \n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,       global_step=global_step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I want to try a 3 layers neural network and see how much I can improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden1_nodes = 1024\n",
    "num_hidden2_nodes = 100\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Initial training, validation, and testing\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, \n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    tf_beta = tf.placeholder(tf.float32)\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken\n",
    "\n",
    "    # hidden layer 1\n",
    "    # It is import to initial neurons with a slightly positive bias to avoid\n",
    "    # \"dead neurons\"\n",
    "    hidden1_weights = tf.Variable(\n",
    "        tf.truncated_normal([image_size * image_size, num_hidden1_nodes],\n",
    "                           stddev = np.sqrt(2.0 / (image_size * image_size))))\n",
    "    hidden1_biases = tf.Variable(tf.zeros([num_hidden1_nodes]))\n",
    "    regu_hidden1 = tf.nn.l2_loss(hidden1_weights)\n",
    "\n",
    "    # hidden layer 2\n",
    "    hidden2_weights = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden1_nodes, num_hidden2_nodes],\n",
    "                           stddev = np.sqrt(2.0 / num_hidden1_nodes)))\n",
    "    hidden2_biases = tf.Variable(tf.zeros([num_hidden2_nodes]))\n",
    "    regu_hidden2 = tf.nn.l2_loss(hidden2_weights)\n",
    "\n",
    "    # output layer\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden2_nodes, num_labels],\n",
    "                           stddev = np.sqrt(2.0 / num_hidden2_nodes)))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "    regu_weights = tf.nn.l2_loss(weights)\n",
    "\n",
    "    # Training computation\n",
    "    hidden1 = tf.nn.relu(tf.matmul(tf_train_dataset, hidden1_weights) + hidden1_biases)\n",
    "#     hidden1_drop = tf.nn.dropout(hidden1, keep_prob)\n",
    "    hidden2 = tf.nn.relu(tf.matmul(hidden1, hidden2_weights) + hidden2_biases)\n",
    "    hidden2_drop = tf.nn.dropout(hidden2, keep_prob)\n",
    "    logits = tf.matmul(hidden2_drop, weights) + biases\n",
    "    loss = tf.reduce_mean(\n",
    "          tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) \\\n",
    "        + tf_beta * (regu_hidden1 + regu_hidden2 + regu_weights)\n",
    "\n",
    "    # Optimizer\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 5000, 0.65, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    # # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_h1 = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden1_weights) + hidden1_biases)\n",
    "    valid_h2 = tf.nn.relu(tf.matmul(valid_h1, hidden2_weights) + hidden2_biases)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "      tf.matmul(valid_h2, weights) + biases)\n",
    "    test_h1 = tf.nn.relu(tf.matmul(tf_test_dataset, hidden1_weights) + hidden1_biases)\n",
    "    test_h2 = tf.nn.relu(tf.matmul(test_h1, hidden2_weights) + hidden2_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_h2, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.311022\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 31.0%\n",
      "Minibatch loss at step 1000: 0.855971\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 2000: 0.850621\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 3000: 0.630466\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 4000: 0.484113\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 5000: 0.570152\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 6000: 0.549380\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 7000: 0.449720\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 8000: 0.490355\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 9000: 0.557347\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 10000: 0.500347\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 11000: 0.506541\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 12000: 0.373652\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 13000: 0.430866\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 14000: 0.494137\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 15000: 0.581972\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 16000: 0.408545\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 17000: 0.482836\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 18000: 0.427820\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 19000: 0.302606\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 90.0%\n",
      "Test accuracy: 95.0%\n",
      "total time: 38407.857383 sec\n"
     ]
    }
   ],
   "source": [
    "num_steps = 19001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    time.clock()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels, \n",
    "                     tf_beta: 1e-3, keep_prob: 0.5}\n",
    "        _, l, predictions = session.run(\n",
    "            [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 1000 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" %(step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "                valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "    print(\"total time: \" + str(time.clock()) + ' sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at using three hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden1_nodes = 1024\n",
    "num_hidden2_nodes = 256\n",
    "num_hidden3_nodes = 50\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Initial training, validation, and testing\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, \n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    tf_beta = tf.placeholder(tf.float32)\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken\n",
    "\n",
    "    # hidden layer 1\n",
    "    # It is import to initial neurons with a slightly positive bias to avoid\n",
    "    # \"dead neurons\"\n",
    "    hidden1_weights = tf.Variable(\n",
    "        tf.truncated_normal([image_size * image_size, num_hidden1_nodes],\n",
    "                           stddev = np.sqrt(2.0 / (image_size * image_size))))\n",
    "    hidden1_biases = tf.Variable(tf.zeros([num_hidden1_nodes]))\n",
    "    regu_hidden1 = tf.nn.l2_loss(hidden1_weights)\n",
    "\n",
    "    # hidden layer 2\n",
    "    hidden2_weights = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden1_nodes, num_hidden2_nodes],\n",
    "                           stddev = np.sqrt(2.0 / num_hidden1_nodes)))\n",
    "    hidden2_biases = tf.Variable(tf.zeros([num_hidden2_nodes]))\n",
    "    regu_hidden2 = tf.nn.l2_loss(hidden2_weights)\n",
    "    \n",
    "    # hidden layer 3\n",
    "    hidden3_weights = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden2_nodes, num_hidden3_nodes],\n",
    "                           stddev = np.sqrt(2.0 / num_hidden2_nodes)))\n",
    "    hidden3_biases = tf.Variable(tf.zeros([num_hidden3_nodes]))\n",
    "    regu_hidden3 = tf.nn.l2_loss(hidden3_weights)\n",
    "\n",
    "    # output layer\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden3_nodes, num_labels],\n",
    "                           stddev = np.sqrt(2.0 / num_hidden3_nodes)))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "    regu_weights = tf.nn.l2_loss(weights)\n",
    "\n",
    "    # Training computation\n",
    "    hidden1 = tf.nn.relu(tf.matmul(tf_train_dataset, hidden1_weights) + hidden1_biases)\n",
    "#     hidden1_drop = tf.nn.dropout(hidden1, keep_prob)\n",
    "    hidden2 = tf.nn.relu(tf.matmul(hidden1, hidden2_weights) + hidden2_biases)\n",
    "#     hidden2_drop = tf.nn.dropout(hidden2, keep_prob)\n",
    "    hidden3 = tf.nn.relu(tf.matmul(hidden2, hidden3_weights) + hidden3_biases)\n",
    "    hidden3_drop = tf.nn.dropout(hidden3, keep_prob)\n",
    "    logits = tf.matmul(hidden3_drop, weights) + biases\n",
    "    loss = tf.reduce_mean(\n",
    "          tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) \\\n",
    "        + tf_beta * (regu_hidden1 + regu_hidden2 + regu_hidden3 + regu_weights)\n",
    "\n",
    "    # Optimizer\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 5000, 0.6, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    # # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_h1 = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden1_weights) + hidden1_biases)\n",
    "    valid_h2 = tf.nn.relu(tf.matmul(valid_h1, hidden2_weights) + hidden2_biases)\n",
    "    valid_h3 = tf.nn.relu(tf.matmul(valid_h2, hidden3_weights) + hidden3_biases)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "      tf.matmul(valid_h3, weights) + biases)\n",
    "    test_h1 = tf.nn.relu(tf.matmul(tf_test_dataset, hidden1_weights) + hidden1_biases)\n",
    "    test_h2 = tf.nn.relu(tf.matmul(test_h1, hidden2_weights) + hidden2_biases)\n",
    "    test_h3 = tf.nn.relu(tf.matmul(test_h2, hidden3_weights) + hidden3_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_h3, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.490894\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 21.6%\n",
      "Minibatch loss at step 2000: 0.810998\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 4000: 0.512680\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 6000: 0.505532\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 8000: 0.542227\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 10000: 0.535631\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 12000: 0.391910\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 14000: 0.496230\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 16000: 0.371045\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 18000: 0.399157\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 20000: 0.399934\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.7%\n",
      "Test accuracy: 95.7%\n",
      "total time: 52736.631537 sec\n"
     ]
    }
   ],
   "source": [
    "num_steps = 20001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    time.clock()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels, \n",
    "                     tf_beta: 1e-3, keep_prob: 0.5}\n",
    "        _, l, predictions = session.run(\n",
    "            [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 2000 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" %(step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "                valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "    print(\"total time: \" + str(time.clock()) + ' sec')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
